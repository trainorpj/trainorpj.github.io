[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a data scientist at the IRS. My background is in computational statistics, but I have experience across the full data science stack.\nPreviously, I worked at:\n\nFormlabs (3D Printing)\nJohns Hopkins Applied Physics Lab (Defense)\n\nI write when I can, which is not as much as I would like to."
  },
  {
    "objectID": "posts/college-football-rankings/index.html",
    "href": "posts/college-football-rankings/index.html",
    "title": "College Football Rankings",
    "section": "",
    "text": "This is a quick-and-dirty implementation Fiddler on the Proof’s Reasonable Rankings for College Football. Their proposal uses the score-differentials between games. Once you have all the scores, you solve a linear equation to rank teams based on how the did against one-another, and even consider how they did amongst similar teams."
  },
  {
    "objectID": "posts/college-football-rankings/index.html#data",
    "href": "posts/college-football-rankings/index.html#data",
    "title": "College Football Rankings",
    "section": "Data",
    "text": "Data\nHere I gather the data for the 2024 season from https://www.sports-reference.com.\n\n\nCode\nfrom  types import SimpleNamespace\n\nimport pandas as pd\nimport duckdb\nimport numpy as np\n\nimport requests\nfrom bs4 import BeautifulSoup\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotnine as pn\n\nurl = \"https://www.sports-reference.com/cfb/years/2024-schedule.html#schedule\"\n\nresponse = requests.get(url)\n\nsoup = BeautifulSoup(response.content)\n\n# Find the table (inspect the webpage to find the correct table tag and attributes)\ntable = soup.find(\"table\", id=\"schedule\")\n\n# use these table headers\nheaders = [\n    \"week\",\n    \"date\",\n    \"time\",\n    \"day\",\n    \"winner\",\n    \"winner_points\",\n    \"home\",\n    \"loser\",\n    \"loser_points\",\n    \"notes\"\n]\n\n# Extract table rows\nrows = []\nfor tr in table.find(\"tbody\").find_all(\"tr\"):\n    row = []\n    for td in tr.find_all(\"td\"):\n        row.append(td.text)\n    rows.append(row)\n\n# Create pandas DataFrame\nscores_raw = (\n    pd.DataFrame(rows, columns=headers)\n    .dropna(subset=[\"week\"])\n)\nscores_raw.iloc[0]\n\n\nweek                              1\ndate                   Aug 24, 2024\ntime                       12:00 PM\nday                             Sat\nwinner                 Georgia Tech\nwinner_points                    24\nhome                              N\nloser            (10) Florida State\nloser_points                     21\nnotes                              \nName: 0, dtype: object\n\n\nHere I clean up the scores table.\n\n\nCode\nscores = duckdb.query(\"\"\"\nwith scores as (\n  select\n    row_number() over() as game_id\n    , trim(regexp_replace(winner, '(\\(\\d+\\))', '')) as winner\n    , trim(regexp_replace(loser, '(\\(\\d+\\))', '')) as loser\n    , cast(coalesce(nullif(winner_points, ''), '0') as int) as winner_points\n    , cast(coalesce(nullif(loser_points, ''), '0') as int) as loser_points\n  from scores_raw\n  where 1=1 and week is not null\n)\nselect\n  *\n  , loser_points\n  , winner_points - loser_points as diff_points\nfrom scores\nwhere 1=1 \n    and winner_points + loser_points &gt; 0\n\"\"\")\n\nduckdb.query(\"select * from scores limit 4\")\n\n\n&lt;&gt;:1: SyntaxWarning: invalid escape sequence '\\('\n&lt;&gt;:1: SyntaxWarning: invalid escape sequence '\\('\n/var/folders/bm/vmrvtfpd56v9sw0pb7c_rp0w0000gp/T/ipykernel_37883/3745766914.py:1: SyntaxWarning: invalid escape sequence '\\('\n\n\n┌─────────┬────────────────────┬────────────────┬───────────────┬──────────────┬────────────────┬─────────────┐\n│ game_id │       winner       │     loser      │ winner_points │ loser_points │ loser_points_1 │ diff_points │\n│  int64  │      varchar       │    varchar     │     int32     │    int32     │     int32      │    int32    │\n├─────────┼────────────────────┼────────────────┼───────────────┼──────────────┼────────────────┼─────────────┤\n│       1 │ Georgia Tech       │ Florida State  │            24 │           21 │             21 │           3 │\n│       2 │ Montana State      │ New Mexico     │            35 │           31 │             31 │           4 │\n│       3 │ Southern Methodist │ Nevada         │            29 │           24 │             24 │           5 │\n│       4 │ Hawaii             │ Delaware State │            35 │           14 │             14 │          21 │\n└─────────┴────────────────────┴────────────────┴───────────────┴──────────────┴────────────────┴─────────────┘\n\n\nConstruct the “game matrix,” which is made up of -1,0,1.\n\nEach row represents a game\nEach column represents a team\nAn entry is 1 if the team won that game, -1 if it lost that game, 0 otherwise\n\nEach game will have a corresponding score, which we keep in another vector.\n\n\nCode\nteams = duckdb.query(\"\"\"\nwith teams as (\n  select distinct winner as team\n  from scores\n  union all\n  select distinct loser as team\n  from scores\n)\nselect team\nfrom teams\norder by team\n\"\"\")\n\nteam_mapping = {team: i for i, team in enumerate(teams.to_df()['team']) }\n\ngame_matrix = np.zeros((scores.shape[0], teams.shape[0]))\nfor i, row in scores.to_df().iterrows():\n  game_matrix[i, team_mapping[row['winner']]] = 1\n  game_matrix[i, team_mapping[row['loser']]] = -1\n\n\"{} games, {} teams\".format(*game_matrix.shape)\n\n\n'919 games, 367 teams'"
  },
  {
    "objectID": "posts/college-football-rankings/index.html#whats-a-game-worth",
    "href": "posts/college-football-rankings/index.html#whats-a-game-worth",
    "title": "College Football Rankings",
    "section": "What’s a game worth?",
    "text": "What’s a game worth?\nThe Fiddler maps a score-differential to a weight between 0 and 1. They recommend the function below. It accepts the number of points the winners won by (i.e. a positive number) and returns a weight between 0 and 1 (1 is better than 0).\n\ndef weigh(points_won_by, alpha:float=1.0):\n  return (2 / (1+np.exp(-points_won_by / alpha))) - 1\n\nThere has a tunable parameter, alpha, which means we can decide how to weigh different wins, e.g. - when alpha=0, “a win is a win,” so a team that wins by 1 point is just as good as a team that wins by 14 points - when alpha=5, a team that wins by 1 point doesn’t get a strong weight (closer to 0), while a team that wins by 14 points gets a weight of ~0.8.\nAs alpha increases, teams need larger point differentials to do well.\n\n\nCode\n(\n  pd.concat([(\n      pd.DataFrame({\"Won By\": np.arange(0, 19)})\n      .assign(alpha=a)\n      .assign(Weight=lambda df: weigh(df[\"Won By\"], alpha=a))\n    ) for a in [0, 1, 2, 5]\n  ], ignore_index=True)\n  .pipe(pn.ggplot)\n    + pn.geom_line(pn.aes(x=\"Won By\", y=\"Weight\", color=\"factor(alpha)\"))\n)\n\n\n/Users/pj/Documents/trainorpj.github.io/.venv/lib/python3.13/site-packages/plotnine/geoms/geom_path.py:100: PlotnineWarning: geom_path: Removed 1 rows containing missing values.\n\n\n\n\n\n\n\n\n\nSo what alpha should we choose? I would work backwards from a score, e.g. “a 14-point (2 touchdowns) win is a decisive win.”\nBelow I’ve plotted the distribution of points the winner won by. We see that 14 points is the median, so my reasoning feels decent.\n\n\nCode\n(\n  # point diff ecdf\n  scores.to_df()\n  .pipe(lambda df: (\n    pn.ggplot(scores.to_df())\n    + pn.stat_ecdf(pn.aes(\"diff_points\"))\n    # plot median\n    + pn.geom_label(x=df.diff_points.median(),y=0.5,label=df.diff_points.median())\n    + pn.labs(title=\"Point Differential ECDF\")\n  ))\n)\n\n\n\n\n\n\n\n\n\nUsing our eyeballs to compare the two plots above, alpha=2 is a reasonable parameter, since it counts 14-point games as a “decisive” victory."
  },
  {
    "objectID": "posts/college-football-rankings/index.html#ranking-the-teams",
    "href": "posts/college-football-rankings/index.html#ranking-the-teams",
    "title": "College Football Rankings",
    "section": "Ranking the Teams",
    "text": "Ranking the Teams\nWith this we can set up a linear equation:\ngames_matrix * team_weights = game_weights\n^known^^^^^^   ^unknown^^^^   ^known^^^^^^        \nAt this point I like to test my assumptions about the shapes and content of my data:\n\nnum_games = scores.shape[0]\nnum_teams = teams.shape[0]\n\nassert game_matrix.shape == (num_games, num_teams)\nassert (game_matrix==1).sum() == num_games # winners get a 1\nassert (game_matrix==-1).sum() == num_games # losers get a -1\n\nexample_game_weights = weigh(scores.to_df().diff_points, 2)\nassert example_game_weights.shape == (num_games,)\nassert ((example_game_weights&gt;=0) & (example_game_weights&lt;=1)).sum() == num_games # values between 0 and 1\n\n\"No errors!\"\n\n'No errors!'\n\n\nNow we can solve this equation. Once we have team_weights, we can pull the top 12 to get our finalists.\n\n\nCode\ndef solve_for_team_weights(games_, teams_, diff_points_, alpha=2):\n  weights = weigh(diff_points_, alpha=alpha)\n  pseudoinverse = np.linalg.pinv(games_)\n  rankings = pseudoinverse @ np.array(weights)\n\n  return pd.Series({\n      team: rankings[i]\n      for i, team in enumerate(teams_.to_df()['team'])\n  })\n\nrankings = solve_for_team_weights(\n  game_matrix, \n  teams,\n  scores.to_df().diff_points\n)\n\n# get top 12\nrankings.sort_values(ascending=False).head(12)\n\n\nOhio State        1.665191\nOregon            1.548168\nNotre Dame        1.468274\nPenn State        1.333366\nTexas             1.324272\nIndiana           1.217931\nGeorgia           1.100962\nIllinois          1.087538\nSouth Carolina    1.084789\nMississippi       1.081674\nBrigham Young     1.078441\nMichigan          1.046878\ndtype: float64"
  },
  {
    "objectID": "posts/college-football-rankings/index.html#sensitivity",
    "href": "posts/college-football-rankings/index.html#sensitivity",
    "title": "College Football Rankings",
    "section": "Sensitivity",
    "text": "Sensitivity\nI’m curious how changing alpha changes the top-12 composition. Recall that increasing alpha means we weigh bigger score differentials more heavily.\nAs we increase alpha, we see that:\n\nOhio State is always #1\nAlabama makes it for alpha&gt;2\nThe higher (i.e. worse) seeds are slightly more competitive\nMiami gets in at alpha~=12\n\n\n\nCode\nsens = SimpleNamespace()\nsens.data = []\nsens.fig, sens.ax = plt.subplots()\n\nfor a in np.linspace(0, 20, 11):\n  sens.tw = (\n    solve_for_team_weights(\n      game_matrix,\n      teams,\n      scores.to_df().diff_points,\n      alpha=a\n    )\n    .sort_values(ascending=False)\n    .head(12)\n    # I don't like pandas\n    .reset_index().rename(columns={\"index\": \"team\", 0: \"team_score\"})\n    .assign(alpha=np.round(a), seed=lambda df: df.index+1)\n  )\n  sens.data.append(sens.tw)\n\n(\n  pd.concat(sens.data, ignore_index=True)\n  .pivot(index=\"team\", columns=\"alpha\", values=\"seed\")\n  # sort by avg rank\n  .pipe(lambda df: df.loc[df.max(axis=1).sort_values().index])\n  .pipe(lambda df: sns.heatmap(df, annot=True, ax=sens.ax))\n)\n\n\n&lt;Axes: xlabel='alpha', ylabel='team'&gt;"
  },
  {
    "objectID": "posts/mtg-similar-cards/index.html",
    "href": "posts/mtg-similar-cards/index.html",
    "title": "MTG LLM Similar Card Search",
    "section": "",
    "text": "This is my first time using LLM embeddings for a program. The goal is to get magic cards similar to a card I’m searching for, which I do quite often.\nMagic cards are quite similar. For example:\nI’d like to use an embedding to\nI used an off-the-shelf model (all-MiniLM-L6-v2), downloaded card data from scryfall, then encoded cards like so:\nIn other words, the model will turn that string into a vector. Ideally, similar strings (i.e. cards) will be near eachother.\nHere I set everything up. I wanted to try using duckdb to query the embeddings.\nCode\nimport pandas as pd\nimport duckdb\nimport numpy as np\nimport json\nfrom pathlib import Path\nfrom sentence_transformers import SentenceTransformer\n\n# Load files\ndata_dir = Path('../../.data')\nembeddings = np.load(data_dir/\"embeddings.npy\")\nwith open(data_dir/\"id_map.json\") as f:\n    id_map = json.load(f)\n\n# load model\nmodel = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n# data prep\nemb_dim = embeddings.shape[1]\ncard_embedding = (\n    pd.DataFrame([\n        {\"id\": card[\"id\"], \"embedding\": vec.tolist()}\n        for card, vec in zip(id_map, embeddings)\n    ])\n)\nparquet_file=data_dir / 'oracle-cards-20250425090226.parquet'\n\n# database\ndb = duckdb.connect(\":memory:\")\ndb.execute(f\"\"\" \nINSTALL vss;\nLOAD vss;\n\ncreate table card_embedding as \n    select \n        id\n        , embedding::DOUBLE[{emb_dim}] as embedding \n    from card_embedding\n;\n\ncreate table card as select * from '{parquet_file}';\n\"\"\")\n\n# how many cards?\ndb.sql('select count(*) as num_cards from card inner join card_embedding using(id)')\n\n\n\n\n\n┌───────────┐\n│ num_cards │\n│   int64   │\n├───────────┤\n│     30189 │\n└───────────┘\nFirst, I need the ability to find the card I’m looking for in the database. I’ll use the embedding for that.\nCode\ndef search_for_card(conn, model, search_term, limit=1):\n    # sentence to vector\n    search_vec = model.encode([search_term])[0]\n    emb_dim = len(search_vec)\n    search_vec_str = \"ARRAY[\" + \",\".join(f\"CAST({x} AS DOUBLE)\" for x in search_vec) + \"]\"\n\n    # find similar vector\n    return conn.sql(f\"\"\"\n    select \n        id             \n        , card.name\n        , array_distance(embedding, {search_vec_str}::DOUBLE[{emb_dim}]) AS dist\n    from card_embedding \n    left join card using(id)\n    order by dist\n    limit {limit}\n    \"\"\")\n\ndef fetch_top_search_id(conn, model, search_term):\n    return search_for_card(conn, model, search_term, limit=1).fetchone()[0]\n\nassert fetch_top_search_id(db, model, 'llanowar elves') == '6a0b230b-d391-4998-a3f7-7b158a0ec2cd'\nNow I want to find similar cards given an id.\nCode\ndef query_closest_cards_to_id(conn, id, limit=9):\n    ref_vec = (\n        conn.sql(f\"select embedding from card_embedding where id='{id}'\")\n        .fetchone()[0]\n    )\n    emb_dim = len(ref_vec)\n    ref_vec_str = \"ARRAY[\" + \",\".join(f\"CAST({x} AS DOUBLE)\" for x in ref_vec) + \"]\"\n\n    return conn.sql(f\"\"\"\n        SELECT \n            card.name\n            , card.mana_cost\n            , card.oracle_text\n            , array_distance(embedding, {ref_vec_str}::DOUBLE[{emb_dim}]) AS dist\n        FROM card_embedding\n        left join card using(id)\n        ORDER BY dist asc\n        LIMIT {limit}\n    \"\"\")\n\nquery_closest_cards_to_id(db, '6a0b230b-d391-4998-a3f7-7b158a0ec2cd')\n\n\n┌───────────────────┬───────────┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────────────────┐\n│       name        │ mana_cost │                                                    oracle_text                                                     │         dist         │\n│      varchar      │  varchar  │                                                      varchar                                                       │        double        │\n├───────────────────┼───────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────────────────┤\n│ Llanowar Elves    │ {G}       │ {T}: Add {G}.                                                                                                      │ 4.58366263816961e-17 │\n│ Llanowar Tribe    │ {G}{G}{G} │ {T}: Add {G}{G}{G}.                                                                                                │   0.4155691829580547 │\n│ Fyndhorn Elves    │ {G}       │ {T}: Add {G}.                                                                                                      │    0.555573984277023 │\n│ Greenweaver Druid │ {2}{G}    │ {T}: Add {G}{G}.                                                                                                   │   0.6204260670261244 │\n│ Elvish Mystic     │ {G}       │ {T}: Add {G}.                                                                                                      │    0.624662550035501 │\n│ Wirewood Elf      │ {1}{G}    │ {T}: Add {G}.                                                                                                      │   0.6288179733631174 │\n│ Llanowar Mentor   │ {G}       │ {G}, {T}, Discard a card: Create a 1/1 green Elf Druid creature token named Llanowar Elves. It has \"{T}: Add {G}.\" │   0.6507426519955598 │\n│ Llanowar Dead     │ {B}{G}    │ {T}: Add {B}.                                                                                                      │   0.6539462847478972 │\n│ Urborg Elf        │ {1}{G}    │ {T}: Add {B}, {G}, or {U}.                                                                                         │   0.6550689705646989 │\n└───────────────────┴───────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴──────────────────────┘\nGluing it all together:\nCode\ndef query_closest_cards_to_search(conn, model, search_term, limit=9):\n    id = fetch_top_search_id(conn, model, search_term)\n    return query_closest_cards_to_id(conn, id, limit=limit)\n\nquery_closest_cards_to_search(db, model, \"llanowar elves\")\n\n\n┌───────────────────┬───────────┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────────────────┐\n│       name        │ mana_cost │                                                    oracle_text                                                     │         dist         │\n│      varchar      │  varchar  │                                                      varchar                                                       │        double        │\n├───────────────────┼───────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────────────────┤\n│ Llanowar Elves    │ {G}       │ {T}: Add {G}.                                                                                                      │ 4.58366263816961e-17 │\n│ Llanowar Tribe    │ {G}{G}{G} │ {T}: Add {G}{G}{G}.                                                                                                │   0.4155691829580547 │\n│ Fyndhorn Elves    │ {G}       │ {T}: Add {G}.                                                                                                      │    0.555573984277023 │\n│ Greenweaver Druid │ {2}{G}    │ {T}: Add {G}{G}.                                                                                                   │   0.6204260670261244 │\n│ Elvish Mystic     │ {G}       │ {T}: Add {G}.                                                                                                      │    0.624662550035501 │\n│ Wirewood Elf      │ {1}{G}    │ {T}: Add {G}.                                                                                                      │   0.6288179733631174 │\n│ Llanowar Mentor   │ {G}       │ {G}, {T}, Discard a card: Create a 1/1 green Elf Druid creature token named Llanowar Elves. It has \"{T}: Add {G}.\" │   0.6507426519955598 │\n│ Llanowar Dead     │ {B}{G}    │ {T}: Add {B}.                                                                                                      │   0.6539462847478972 │\n│ Urborg Elf        │ {1}{G}    │ {T}: Add {B}, {G}, or {U}.                                                                                         │   0.6550689705646989 │\n└───────────────────┴───────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴──────────────────────┘"
  },
  {
    "objectID": "posts/mtg-mana-problems/index.html",
    "href": "posts/mtg-mana-problems/index.html",
    "title": "Simulating Magic’s Mana Problems",
    "section": "",
    "text": "This post puts numbers to common “mana problems” in Magic: The Gathering. If you don’t play Magic, this is about using simulation instead of traditional probability distributions (i.e. the oft-misunderstood hypergeometric distribution).\nIn Magic, there are generally two types of cards:\nA deck of cards typically has 23 spells and 17 lands. You start with 7 cards, and draw a card each turn. If you have 7 spells in-hand (and therefore 0 lands), you can’t actually cast them until you draw lands.\nHere’s an example starting hand from a shuffled deck.\nCode\nimport pandas as pd\nimport duckdb\nimport numpy as np\nfrom scipy import stats\nimport plotnine as pn\n\ndef make_deck():\n    deck = [\"Land\" for _ in range(17)]\n    deck.extend([\"Spell\" for _ in range(23)])\n    np.random.shuffle(deck)\n    return deck\n\ndef get_counts(cards):\n    return pd.Series(cards).value_counts()\n\n# example first hand\nget_counts(make_deck()[:7])\n\n\nSpell    4\nLand     3\nName: count, dtype: int64\nHow many lands should we expect to have in our opening hand? Probability textbooks would suggest the hypergeometric distribution, but I suggest using simulation instead.\nThe plot below shows that ~50% of the time we have 3 or 4 lands, which is a healthy ideal number.\nI’ve also included the actual hypergeometric distribution values to check my work. They match up, but I think the simulation is much easier to follow.\nCode\nnum_sim = 601\nopening_hands = (\n    pd.DataFrame({\n        # shuffle the deck, draw 7 cards from the top, count the lands\n        i: get_counts(make_deck()[:7])\n        for i in range(num_sim)\n    })\n    .T\n    .fillna(0)\n)\n\n# the actual distribution\nhg = stats.hypergeom(40, 17, 7)\nhg_cdf = pd.DataFrame({\"Land\": np.arange(0, 7)})\nhg_cdf[\"cdf\"] = hg.cdf(hg_cdf.Land)\n\n# print results\nprint(duckdb.query(f\"\"\" \nselect \n    count(*) filter(Land between 3 and 4) / count(*) as sim_frac_3_4\n    , {hg.pmf(3) + hg.pmf(4)} as actual_frac_3_4\nfrom opening_hands \n\"\"\"))\n\n# plots cdfs\n(\n    pn.ggplot(data=opening_hands) +\n    pn.geom_col(hg_cdf, pn.aes(\"Land\", \"cdf\"), fill=\"white\") +\n    pn.stat_ecdf(pn.aes(\"Land\")) +\n    pn.labs(title=\"Opening Hand Num Lands CDF\", subtitle=\"Bars show stats.hypergeom(40, 17, 7) CDF\")\n)\n\n\n┌──────────────────┬────────────────────┐\n│   sim_frac_3_4   │  actual_frac_3_4   │\n│      double      │   decimal(17,16)   │\n├──────────────────┼────────────────────┤\n│ 0.56738768718802 │ 0.5490571543203121 │\n└──────────────────┴────────────────────┘\nSuppose you decide to keep any hand, e.g. one with 2 lands and 5 spells. You’ll draw a card each turn, so how many lands should you expect to get?\nFirst we’ll set up a function to simulate this. Here we get the cumulative counts of spells and lands after each draw.\nCode\ndef get_turn_counts(deck, num_start=7, num_draws=6):\n    counts = {\n        i: get_counts(deck[:(num_start+i)])\n        for i in range(num_draws+1)\n    }\n    return (\n        pd.DataFrame(counts).T\n        .reset_index(names=[\"draw\"])\n        .fillna(0)\n    )\n\n# example\nget_turn_counts(make_deck())\n\n\n\n\n\n\n\n\n\ndraw\nLand\nSpell\n\n\n\n\n0\n0\n5\n2\n\n\n1\n1\n6\n2\n\n\n2\n2\n7\n2\n\n\n3\n3\n8\n2\n\n\n4\n4\n8\n3\n\n\n5\n5\n9\n3\n\n\n6\n6\n9\n4\nNow we’ll simulate many draws and tally the results. We see that:\nCode\ndraw_sims = (\n    pd.concat([\n        get_turn_counts(make_deck()).assign(sim_id=i)\n        for i in range(num_sim)\n    ], ignore_index=True)\n)\n\n(\n    duckdb.sql(\"\"\"\n    select \n        draw\n        , Land\n        , count(*) as num\n        , SUM(COUNT(*)) OVER (partition by draw) as num_draws\n        , num / num_draws AS draw_frac\n    from draw_sims\n    group by draw, Land\n    order by draw\n    \"\"\")\n    .to_df()\n    .pipe(pn.ggplot)\n    + pn.geom_tile(pn.aes(\"draw\", \"Land\", fill=\"draw_frac\"))\n    + pn.geom_text(pn.aes(\"draw\", \"Land\", label=\"round(draw_frac, 2)\"))\n    + pn.scale_fill_continuous(cmap_name=\"Blues\")\n    + pn.labs(y=\"total lands drawn\", x=\"draw\")\n)\nSuppose you have drawn an opening hand with only two lands (~10% chance). What should you expect to see in the coming draws? Here we’ll draw out the cdf for each draw.\nWe see that by your 2nd draw, there’s a good chance you have 3 or 4 lands.\nCode\nprint(duckdb.sql(\"\"\"select count(*) filter(Land=2) as \"Num Two-Land Openers\" from draw_sims\"\"\"))\n\n(\n    duckdb.sql(\"\"\" \n    select \n        draw\n        , Land\n        , count(*) as num\n        , SUM(COUNT(*)) OVER (partition by draw) as num_draws\n        , num / num_draws AS draw_frac\n    from (\n        select sim_id\n        from draw_sims\n        where draw=0 and Land=2\n    ) as two_land_openers \n    left join draw_sims using(sim_id)\n    where 1=1 \n        and draw &gt; 0 -- first draw will always have Land=2\n    group by draw, Land\n    order by draw\n    \"\"\")\n    .to_df().pipe(pn.ggplot)\n    + pn.stat_ecdf(pn.aes(\"Land\"), geom=\"col\") \n    + pn.facet_wrap(\"draw\", labeller=\"label_both\")\n)\n\n\n┌──────────────────────┐\n│ Num Two-Land Openers │\n│        int64         │\n├──────────────────────┤\n│                  434 │\n└──────────────────────┘\n\n\n\n/Users/pj/Documents/trainorpj.github.io/.venv/lib/python3.13/site-packages/numpy/_core/_methods.py:135: RuntimeWarning: invalid value encountered in reduce\n/Users/pj/Documents/trainorpj.github.io/.venv/lib/python3.13/site-packages/numpy/_core/_methods.py:135: RuntimeWarning: invalid value encountered in reduce\n/Users/pj/Documents/trainorpj.github.io/.venv/lib/python3.13/site-packages/numpy/_core/_methods.py:135: RuntimeWarning: invalid value encountered in reduce\n/Users/pj/Documents/trainorpj.github.io/.venv/lib/python3.13/site-packages/numpy/_core/_methods.py:135: RuntimeWarning: invalid value encountered in reduce\n/Users/pj/Documents/trainorpj.github.io/.venv/lib/python3.13/site-packages/numpy/_core/_methods.py:135: RuntimeWarning: invalid value encountered in reduce\n/Users/pj/Documents/trainorpj.github.io/.venv/lib/python3.13/site-packages/numpy/_core/_methods.py:135: RuntimeWarning: invalid value encountered in reduce"
  },
  {
    "objectID": "posts/mtg-mana-problems/index.html#mulligans",
    "href": "posts/mtg-mana-problems/index.html#mulligans",
    "title": "Simulating Magic’s Mana Problems",
    "section": "Mulligans",
    "text": "Mulligans\nYou have the option to “mulligan” your opening hand, i.e. you can shuffle, re-draw 7 cards, then put one on the bottom of your deck.\n\nThis is another benefit of simulation. I don’t even want to bother finding the probability distribution for this. Even if I could figure it out, I wouldn’t want to explain it to other people. People can understand code.\n\nHere’s some janky mulligan logic. I wrote a check at the bottom to see how often we get different starting hand sizes. ~80% of the time we have 7 or 6 cards to start.\n\n\nCode\ndef mulligan_keep_check(hand) -&gt; bool:\n    counts = get_counts(hand)\n    num_lands = 0 if \"Land\" not in counts.keys() else counts.Land\n    if 3 &lt;= num_lands &lt;= 4:\n        return True\n    return False\n\ndef mulligan_choice(hand, num_mulligan: int):\n    # Choose as many lands as you can ... not ideal, but I didn't feel\n    # like doing something more sophisticated\n    hand = sorted(hand)\n    new_hand, bottom = hand[:-num_mulligan], hand[-num_mulligan:]\n    return new_hand, bottom\n\nassert mulligan_choice(list(\"SLSSSLS\"), 2) == ([\"L\", \"L\", \"S\", \"S\", \"S\"], [\"S\", \"S\"])\n\ndef make_deck_with_mulligan(\n    num_start=7, \n    max_mulligans=2,\n    mulligan_keep_check_fcn=mulligan_keep_check,\n    mulligan_choice_fcn=mulligan_choice\n):\n    # setup\n    keep_hand = False\n    num_mulligans = -1\n\n    # mulligan until you reach your max, or until you decide to keep\n    while all([\n        num_mulligans &lt; max_mulligans, \n        not keep_hand\n    ]):\n        # this only updates when keep is False\n        num_mulligans += 1\n        \n        # split up and and deck\n        deck = make_deck()\n        hand, rest_of_deck = deck[:num_start], deck[num_start:]\n\n        # update state\n        keep_hand = mulligan_keep_check_fcn(hand)\n    \n    if num_mulligans &gt; 0:\n        new_hand, bottom = mulligan_choice(hand, num_mulligans)\n        num_start = len(new_hand)\n        deck = [*new_hand,*rest_of_deck,*bottom]\n\n    return deck, num_start\n\n# check opening hand sizes w/ mulligans\npd.Series([make_deck_with_mulligan()[1] for _ in range(201)]).value_counts(normalize=True).sort_index()\n\n\n5    0.174129\n6    0.208955\n7    0.616915\nName: proportion, dtype: float64\n\n\nThe table and plot below show how it changes our opening hands. We go from a 60% chance of having 3-4 lands to a 90% chance after we mulligan.\nThat’s a pretty strong case for choosing a mulligan!\n\n\nCode\n# [(deck, num_start)]\nmull_sim_decks = [make_deck_with_mulligan() for _ in range(num_sim)]\nmull_sim_draws = pd.concat([\n    get_turn_counts(deck, num_start=num_start).assign(sim_id=i, num_start=num_start)\n    for i, (deck, num_start) in enumerate(mull_sim_decks)\n], ignore_index=True)\n\ncomb_sims = duckdb.query(\"\"\"\nselect 'no-mull' as strategy, draw, land, 7 as num_start\nfrom draw_sims\nunion all by name\nselect 'mull' as strategy, draw, land, num_start\nfrom mull_sim_draws\n\"\"\")\n\nprint(duckdb.query(\"\"\" \nselect\n    strategy\n    , sum(land between 3 and 4) as num_3_4\n    , count(*) num_sims\n    , round(num_3_4 / num_sims, 2) as frac_3_4\nfrom comb_sims\nwhere 1=1 and draw = 0\ngroup by strategy\n\"\"\"))\n\n(\n    duckdb.query(\"\"\" \n    select\n        strategy\n        , land\n        , count(*) as num\n        , SUM(COUNT(*)) OVER (partition by strategy) as num_draws\n        , num / num_draws AS draw_frac\n    from comb_sims\n    where 1=1 and draw = 0\n    group by strategy, land\n    \"\"\")\n    .to_df().pipe(pn.ggplot)\n    + pn.stat_ecdf(pn.aes(x=\"Land\", fill=\"strategy\"), geom=\"col\", position=\"dodge\")\n)\n\n\n┌──────────┬─────────┬──────────┬──────────┐\n│ strategy │ num_3_4 │ num_sims │ frac_3_4 │\n│ varchar  │ int128  │  int64   │  double  │\n├──────────┼─────────┼──────────┼──────────┤\n│ no-mull  │     336 │      601 │     0.56 │\n│ mull     │     545 │      601 │     0.91 │\n└──────────┴─────────┴──────────┴──────────┘\n\n\n\n/Users/pj/Documents/trainorpj.github.io/.venv/lib/python3.13/site-packages/numpy/_core/_methods.py:135: RuntimeWarning: invalid value encountered in reduce\n/Users/pj/Documents/trainorpj.github.io/.venv/lib/python3.13/site-packages/plotnine/layer.py:364: PlotnineWarning: geom_col : Removed 4 rows containing missing values."
  },
  {
    "objectID": "posts/mtg-mana-problems/index.html#where-to-go-next",
    "href": "posts/mtg-mana-problems/index.html#where-to-go-next",
    "title": "Simulating Magic’s Mana Problems",
    "section": "Where to go next",
    "text": "Where to go next\nSome other directions to take this:\n\nThe composition of your deck is hugely important to what spells you can play. If most of your spells only cost one mana (i.e. land), can you live with only one or two lands in your starting hand?\nCan we incorporate that into our mulligan decisions? I made the mulligan function flexible enough that you can try different strategies.\nWhat is the ideal number of lands? Conventional wisdom (I’m sure backed up by math) says 17 is the ideal number."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "MTG LLM Similar Card Search\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating Magic’s Mana Problems\n\n\n\n\n\n\n\n\n\n\n\nApr 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCollege Football Rankings\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/mtg-similar-cards/index.html#eyeball-evaluation",
    "href": "posts/mtg-similar-cards/index.html#eyeball-evaluation",
    "title": "MTG LLM Similar Card Search",
    "section": "Eyeball Evaluation",
    "text": "Eyeball Evaluation\nThis ordering is not perfect. For example:\n\nLlanowar Tribe│ {G}{G}{G} │ {T}: Add {G}{G}{G}. is the “top” result\nFyndhorn Elves    │ {G}       │ {T}: Add {G}. and other cards functionally identical to Llanowar Elves are rated lower.\n\nI think this happens because I encode the name of the card in the embedding, which I chose to make search easier.\n\nPerhaps I should make two embeddings if my use-case is scoped this narrowly.\nThe tradeoff is that I would need another API to do generalized search e.g. “{T}: Add {G}”"
  },
  {
    "objectID": "posts/mtg-similar-cards/index.html#extending",
    "href": "posts/mtg-similar-cards/index.html#extending",
    "title": "MTG LLM Similar Card Search",
    "section": "Extending",
    "text": "Extending\nWe can make the query more flexible to account for different contexts. With this we combine the power of traditional querying with vector search.\n\n\nCode\ndef sql_array_distance_from_search(conn, model, search_term):\n    id = fetch_top_search_id(conn, model, search_term)\n    ref_vec = (\n        conn.sql(f\"select embedding from card_embedding where id='{id}'\")\n        .fetchone()[0]\n    )\n    emb_dim = len(ref_vec)\n    ref_vec_str = \"ARRAY[\" + \",\".join(f\"CAST({x} AS DOUBLE)\" for x in ref_vec) + \"]\"\n    return f\"array_distance(embedding, {ref_vec_str}::DOUBLE[{emb_dim}])\"\n\ndb.sql(f\"\"\" \nselect \n    name\n    , oracle_text\n    , {sql_array_distance_from_search(db, model, 'when you cycle')} as dist\nfrom card_embedding\nleft join card using(id)\nwhere 1=1\n    and layout = 'normal'\n    and cmc = 2\norder by dist asc\nlimit 9\n\"\"\")\n\n\n┌────────────────────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬───────────────────────┐\n│          name          │                                                                   oracle_text                                                                   │         dist          │\n│        varchar         │                                                                     varchar                                                                     │        double         │\n├────────────────────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────────┤\n│ Drannith Healer        │ Whenever you cycle another card, you gain 1 life.\\nCycling {1} ({1}, Discard this card: Draw a card.)                                           │ 4.804520544858501e-17 │\n│ Drannith Stinger       │ Whenever you cycle another card, this creature deals 1 damage to each opponent.\\nCycling {1} ({1}, Discard this card: Draw a card.)             │    0.7654649610995645 │\n│ Witherbloom Apprentice │ Magecraft — Whenever you cast or copy an instant or sorcery spell, each opponent loses 1 life and you gain 1 life.                              │    0.9166975304148206 │\n│ Blessed Wine           │ You gain 1 life.\\nDraw a card at the beginning of the next turn's upkeep.                                                                       │    0.9202103106272829 │\n│ Revitalize             │ You gain 3 life.\\nDraw a card.                                                                                                                  │    0.9227281467739591 │\n│ Disciple of Law        │ Protection from red\\nCycling {2} ({2}, Discard this card: Draw a card.)                                                                         │    0.9279500413320395 │\n│ Soul Shepherd          │ {W}, Exile a creature card from your graveyard: You gain 1 life.                                                                                │    0.9443892064122495 │\n│ Syndic of Tithes       │ Extort (Whenever you cast a spell, you may pay {W/B}. If you do, each opponent loses 1 life and you gain that much life.)                       │     0.950814787176584 │\n│ Samite Herbalist       │ Whenever this creature becomes tapped, you gain 1 life and scry 1. (Look at the top card of your library. You may put that card on the bottom.) │    0.9514616126869583 │\n└────────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────┘"
  },
  {
    "objectID": "posts/mtg-similar-cards/index.html#whats-next",
    "href": "posts/mtg-similar-cards/index.html#whats-next",
    "title": "MTG LLM Similar Card Search",
    "section": "What’s next?",
    "text": "What’s next?\nI think I need better recommendations before I go any further. The results need to be “good enough,” but they’re not quite there. I’ll have to look into what it takes to refine the model for my use-case.\nMaking an app (probably a simple webapp) would be the most helpful interface. Even 5-10 recommendations would be helpful."
  }
]