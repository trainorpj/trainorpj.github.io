[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a data scientist at the IRS. My background is in computational statistics, but I have interest (and lots of experience) across the full data science stack.\nPreviously, I worked at:\n\nFormlabs (3D Printing)\nJohns Hopkins Applied Physics Lab (Defense)\n\nI write when I can, which is not as much as I would like to."
  },
  {
    "objectID": "posts/20252020-college-football-rankings/index.html",
    "href": "posts/20252020-college-football-rankings/index.html",
    "title": "College Football Rankings",
    "section": "",
    "text": "This is a quick-and-dirty implementation and extension of Fiddler on the Proof’s Reasonable Rankings for College Football."
  },
  {
    "objectID": "posts/20252020-college-football-rankings/index.html#data",
    "href": "posts/20252020-college-football-rankings/index.html#data",
    "title": "College Football Rankings",
    "section": "Data",
    "text": "Data\nYou can skip this part if you’d like.\n\n\nCode\nfrom  types import SimpleNamespace\n\nimport pandas as pd\nimport duckdb\nimport numpy as np\n\nimport requests\nfrom bs4 import BeautifulSoup\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nurl = \"https://www.sports-reference.com/cfb/years/2024-schedule.html#schedule\"\n\nresponse = requests.get(url)\n\nsoup = BeautifulSoup(response.content)\n\n# Find the table (inspect the webpage to find the correct table tag and attributes)\ntable = soup.find(\"table\", id=\"schedule\")\n\n# use these table headers\nheaders = [\n    \"week\",\n    \"date\",\n    \"time\",\n    \"day\",\n    \"winner\",\n    \"winner_points\",\n    \"home\",\n    \"loser\",\n    \"loser_points\",\n    \"notes\"\n]\n\n# Extract table rows\nrows = []\nfor tr in table.find(\"tbody\").find_all(\"tr\"):\n    row = []\n    for td in tr.find_all(\"td\"):\n        row.append(td.text)\n    rows.append(row)\n\n# Create pandas DataFrame\nscores_raw = (\n    pd.DataFrame(rows, columns=headers)\n    .dropna(subset=[\"week\"])\n)\nscores_raw.iloc[0]\n\n\nweek                              1\ndate                   Aug 24, 2024\ntime                       12:00 PM\nday                             Sat\nwinner                 Georgia Tech\nwinner_points                    24\nhome                              N\nloser            (10) Florida State\nloser_points                     21\nnotes                              \nName: 0, dtype: object\n\n\nCleanup.\n\n\nCode\nscores = duckdb.query(\"\"\"\nwith scores as (\n  select\n    row_number() over() as game_id\n    , trim(regexp_replace(winner, '(\\(\\d+\\))', '')) as winner\n    , trim(regexp_replace(loser, '(\\(\\d+\\))', '')) as loser\n    , cast(coalesce(nullif(winner_points, ''), '0') as int) as winner_points\n    , cast(coalesce(nullif(loser_points, ''), '0') as int) as loser_points\n  from scores_raw\n  where 1=1 and week is not null\n)\nselect\n  *\n  , loser_points\n  , winner_points - loser_points as diff_points\nfrom scores\nwhere 1=1 \n    and winner_points + loser_points &gt; 0\n\"\"\")\n\nduckdb.query(\"select * from scores limit 4\")\n\n\n&lt;&gt;:1: SyntaxWarning: invalid escape sequence '\\('\n&lt;&gt;:1: SyntaxWarning: invalid escape sequence '\\('\n/var/folders/bm/vmrvtfpd56v9sw0pb7c_rp0w0000gp/T/ipykernel_23445/3745766914.py:1: SyntaxWarning: invalid escape sequence '\\('\n  scores = duckdb.query(\"\"\"\n\n\n┌─────────┬────────────────────┬────────────────┬───────────────┬──────────────┬────────────────┬─────────────┐\n│ game_id │       winner       │     loser      │ winner_points │ loser_points │ loser_points_1 │ diff_points │\n│  int64  │      varchar       │    varchar     │     int32     │    int32     │     int32      │    int32    │\n├─────────┼────────────────────┼────────────────┼───────────────┼──────────────┼────────────────┼─────────────┤\n│       1 │ Georgia Tech       │ Florida State  │            24 │           21 │             21 │           3 │\n│       2 │ Montana State      │ New Mexico     │            35 │           31 │             31 │           4 │\n│       3 │ Southern Methodist │ Nevada         │            29 │           24 │             24 │           5 │\n│       4 │ Hawaii             │ Delaware State │            35 │           14 │             14 │          21 │\n└─────────┴────────────────────┴────────────────┴───────────────┴──────────────┴────────────────┴─────────────┘\n\n\nMake the game matrix. We’ll discuss this later.\n\n\nCode\nteams = duckdb.query(\"\"\"\nwith teams as (\n  select distinct winner as team\n  from scores\n  union all\n  select distinct loser as team\n  from scores\n)\nselect team\nfrom teams\norder by team\n\"\"\")\n\nteam_mapping = {team: i for i, team in enumerate(teams.to_df()['team']) }\n\ngame_matrix = np.zeros((scores.shape[0], teams.shape[0]))\nfor i, row in scores.to_df().iterrows():\n  game_matrix[i, team_mapping[row['winner']]] = 1\n  game_matrix[i, team_mapping[row['loser']]] = -1\n\ngame_matrix.shape\n\n\n(919, 367)"
  },
  {
    "objectID": "posts/20252020-college-football-rankings/index.html#whats-a-game-worth",
    "href": "posts/20252020-college-football-rankings/index.html#whats-a-game-worth",
    "title": "College Football Rankings",
    "section": "What’s a game worth?",
    "text": "What’s a game worth?\nTo simplify the modeling, we want to map a score-differential to a weight between 0 and 1. This is the function they recommend. It accepts the number of points the winners won by (i.e. a positive number) and returns a weight between 0 and 1 (1 is better than 0).\n\ndef weigh(points_won_by, alpha=1):\n  return (2 / (1+np.exp(-points_won_by / alpha))) - 1\n\nThere has a tunable parameter, alpha, which means we can decide how to weigh different wins, e.g. - when alpha=0, “a win is a win,” so a team that wins by 1 point is just as good as a team that wins by 14 points - when alpha=5, a team that wins by 1 point doesn’t get a strong weight (closer to 0), while a team that wins by 14 points gets a weight of ~0.8.\nAs alpha increases, teams need larger point differentials to do well.\n\n\nCode\npd.concat([\n  pd.DataFrame({\"Won By\": np.arange(0, 2*7)})\\\n    .assign(alpha=a)\\\n    .assign(Weight=lambda df: weigh(df[\"Won By\"], alpha=a))\n  for a in [0, 1, 2, 5]\n  ], ignore_index=True)\\\n  .pipe(lambda df: sns.relplot(data=df, x=\"Won By\", y=\"Weight\", hue=\"alpha\", kind=\"line\"))\n\n\n\n\n\n\n\n\n\nSo what alpha should we choose? I would work backwards from a score, e.g. “a 14-point (2 touchdowns) win is a decisive win.” If we look at the distribution of points the winner won by, we see 14 points is the median, so that’s a decent sanity check.\n\n\nCode\nsns.displot(data=scores.to_df(), x=\"diff_points\", kind=\"ecdf\")\n\n\n\n\n\n\n\n\n\nUsing our eyeballs, the plot above shows alpha=2 is a reasonable parameter. Here’s where all the weights would land:\n\nThe plot on the left is the diff_score -&gt; weight mapping, and the plot on the right is a flipped ecdf of the resulting weights, so the ecdf is actually on the x-axis.\n\n\n\nCode\n# I use SimpleNamespace to keep things tidy.\nwex = SimpleNamespace()\n\nwex.fig, wex.ax = plt.subplots(1, 2)\n\nwex.data = scores.to_df().assign(weight=lambda df: weigh(df.diff_points, alpha=2))\n\nsns.lineplot(x=wex.data.diff_points, y=wex.data.weight, ax=wex.ax[0])\nsns.ecdfplot(y=wex.data.weight, ax=wex.ax[1])"
  },
  {
    "objectID": "posts/20252020-college-football-rankings/index.html#ranking-the-teams",
    "href": "posts/20252020-college-football-rankings/index.html#ranking-the-teams",
    "title": "College Football Rankings",
    "section": "Ranking the Teams",
    "text": "Ranking the Teams\nWith this we can set up a linear equation:\ngames_matrix * team_weights = game_weights\n^known^^^^^^   ^unknown^^^^   ^known^^^^^^        \nWhere\ngames_matrix:\n  shape: (num_games, num_teams)\n  values: 1 for the winner, -1 for the loser, 0 otherwise\n\nteam_weights:\n  shape: (num_teams, 1)\n\ngame_weights:\n  shape: (num_games, 1)\n  values: between 0 and 1\n\n\nCode\nnum_games = scores.shape[0]\nnum_teams = teams.shape[0]\n\nassert game_matrix.shape == (num_games, num_teams)\n# each winner gets a 1\nassert (game_matrix==1).sum() == num_games\n# each loser gets a -1\nassert (game_matrix==-1).sum() == num_games\n\nexample_game_weights = weigh(scores.to_df().diff_points, 2)\nassert example_game_weights.shape == (num_games,)\n# every value between 0 and 1\nassert ((example_game_weights&gt;=0) & (example_game_weights&lt;=1)).sum() == num_games\n\n\nSolving for this:\n\n\nCode\ndef solve_for_team_weights(games, weights, teams=teams):\n  pseudoinverse = np.linalg.pinv(games)\n  rankings = pseudoinverse @ np.array(weights)\n\n  return pd.Series({\n      team: rankings[i]\n      for i, team in enumerate(teams.to_df()['team'])\n  })\n\nrankings = solve_for_team_weights(\n  game_matrix, \n  weigh(scores.to_df().diff_points, 2),\n  teams\n)\n\n# get top 12\nrankings.sort_values(ascending=False).head(12)\n\n\nOhio State        1.665191\nOregon            1.548168\nNotre Dame        1.468274\nPenn State        1.333366\nTexas             1.324272\nIndiana           1.217931\nGeorgia           1.100962\nIllinois          1.087538\nSouth Carolina    1.084789\nMississippi       1.081674\nBrigham Young     1.078441\nMichigan          1.046878\ndtype: float64"
  },
  {
    "objectID": "posts/20252020-college-football-rankings/index.html#sensitivity",
    "href": "posts/20252020-college-football-rankings/index.html#sensitivity",
    "title": "College Football Rankings",
    "section": "Sensitivity",
    "text": "Sensitivity\nI’m curious how changing alpha changes the top-12 composition. Recall that increasing alpha means we weigh bigger score differentials more heavily.\nAs we increase alpha, we see that:\n\nOhio State is always #1\nAlabama makes it for alpha&gt;2\nThe higher (i.e. worse) seeds are slightly more competitive\nMiami gets in at alpha~=12\n\n\n\nCode\nsens = SimpleNamespace()\nsens.data = []\nsens.fig, sens.ax = plt.subplots()\n\nfor a in np.linspace(0, 20, 11):\n  sens.tw = (\n    solve_for_team_weights(\n      game_matrix,\n      weigh(scores.to_df().diff_points, a),\n      teams\n    )\n    .sort_values(ascending=False)\n    .head(12)\n    # I don't like pandas\n    .reset_index().rename(columns={\"index\": \"team\", 0: \"team_score\"})\n    .assign(alpha=np.round(a), seed=lambda df: df.index+1)\n  )\n  sens.data.append(sens.tw)\n\n(\n  pd.concat(sens.data, ignore_index=True)\n  .pivot(index=\"team\", columns=\"alpha\", values=\"seed\")\n  # sort by avg rank\n  .pipe(lambda df: df.loc[df.max(axis=1).sort_values().index])\n  .pipe(lambda df: sns.heatmap(df, annot=True, ax=sens.ax))\n)"
  },
  {
    "objectID": "posts/meta/quick-and-dirty/index.html",
    "href": "posts/meta/quick-and-dirty/index.html",
    "title": "Quick and Dirty",
    "section": "",
    "text": "Some posts will have the “quick-and-dirty” tag. These are meant to communicate an idea quickly. These are written (and coded) in a stream-of-conciousness fashion, and they’re mostly a tool for me to get things done.\nProfessionally, I think most of my work is quick-and-dirty. If my manager asks for a quick analysis, I want to get them accurate results as quickly as possible. Nobody cares how clean/reusable my code is if nobody is sees it. Most of the time, cleaning up you python/SQL/whatever is not worth the effort."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "College Football Rankings\n\n\n\n\n\n\nquick-and-dirty\n\n\n\n\n\n\n\n\n\nFeb 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nQuick and Dirty\n\n\n\n\n\n\nmeta\n\n\n\n\n\n\n\n\n\nFeb 19, 2025\n\n\n\n\n\n\nNo matching items"
  }
]